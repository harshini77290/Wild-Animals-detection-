{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH8o_qBp2HBi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Function to extract features from an audio file\n",
        "def extract_features(audio_path):\n",
        "    try:\n",
        "        audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=20)\n",
        "        # Add other features as needed\n",
        "        features = np.mean(mfccs, axis=1)\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Specify the root directory of your dataset\n",
        "dataset_root = '/content/drive/MyDrive/Animal_Dataset'\n",
        "\n",
        "# Define the classes (animal names)\n",
        "classes = ['Birds', 'Elephant', 'Leopard', 'Otter', 'Tiger']\n",
        "\n",
        "X = []  # List to store features\n",
        "y = []  # List to store labels\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in classes:\n",
        "    class_folder = os.path.join(dataset_root, class_name)\n",
        "\n",
        "    # Iterate through audio files in the class folder\n",
        "    for audio_file in os.listdir(class_folder):\n",
        "        audio_path = os.path.join(class_folder, audio_file)\n",
        "\n",
        "        # Extract features from the audio file\n",
        "        features = extract_features(audio_path)\n",
        "\n",
        "        if features is not None:\n",
        "            X.append(features)\n",
        "            y.append(classes.index(class_name))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Now, X contains your feature matrix, and y contains the corresponding labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgskiRR078Gf",
        "outputId": "a850b496-044a-4ab1-b7d3-dd847edcf349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-597.7563     -37.171284   -41.327328  ...    1.2677945   -5.098191\n",
            "     2.12892  ]\n",
            " [-560.7332      -8.476901   -27.771772  ...    1.220307     2.7622428\n",
            "    -1.9266127]\n",
            " [-526.71216    -78.22412    -76.27306   ...  -10.779298     7.3135214\n",
            "     8.441823 ]\n",
            " ...\n",
            " [-271.472      173.8646     -36.965656  ...  -12.830008   -10.297043\n",
            "    -4.864692 ]\n",
            " [-261.2718     163.21481    -36.95614   ...   -9.914326    -7.5772476\n",
            "    -7.423172 ]\n",
            " [-276.2054     159.80583    -33.212875  ...  -11.813957    -9.561474\n",
            "    -6.111332 ]]\n",
            "[0 0 0 ... 4 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have a dataset (X, y)\n",
        "# X is your feature matrix, and y is your label vector\n",
        "\n",
        "# Convert labels to categorical if it's a classification problem\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model\n",
        "input_length = X_train.shape[1]  # Adjust based on your features\n",
        "num_features = X_train.shape[1]  # Adjust based on your features (modified to match X_train's shape)\n",
        "num_classes = y_categorical.shape[1]  # Adjust based on your number of classes\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(input_length, 1)))  # Modified input_shape\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define training parameters\n",
        "epochs = 10  # Adjust based on your preference\n",
        "batch_size = 32  # Adjust based on your preference and hardware constraints\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/Features_Output/your_trained_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeccLx0W8Dvn",
        "outputId": "6c93563c-aa2e-4333-fb69-a82423f70e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 5s 25ms/step - loss: 1.2607 - accuracy: 0.6562 - val_loss: 0.6474 - val_accuracy: 0.7681\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 1s 13ms/step - loss: 0.6209 - accuracy: 0.7865 - val_loss: 0.5836 - val_accuracy: 0.8083\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5537 - accuracy: 0.8066 - val_loss: 0.6554 - val_accuracy: 0.7597\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5483 - accuracy: 0.8118 - val_loss: 0.6170 - val_accuracy: 0.7944\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.8215 - val_loss: 0.6080 - val_accuracy: 0.8083\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.5033 - accuracy: 0.8274 - val_loss: 0.7475 - val_accuracy: 0.7306\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5128 - accuracy: 0.8302 - val_loss: 0.5679 - val_accuracy: 0.8069\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4954 - accuracy: 0.8267 - val_loss: 0.5154 - val_accuracy: 0.8264\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4801 - accuracy: 0.8399 - val_loss: 0.5619 - val_accuracy: 0.8139\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4846 - accuracy: 0.8306 - val_loss: 0.5452 - val_accuracy: 0.8042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Load the saved model\n",
        "model_path = '/content/drive/MyDrive/Features_Output/your_trained_model.h5'\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "def extract_and_preprocess_features(audio_path, expected_shape):\n",
        "    try:\n",
        "        # Load the new audio file\n",
        "        audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "\n",
        "        # Extract MFCCs, ZCR, Mel spectrogram, and Chroma features (adjust as needed)\n",
        "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "\n",
        "        # Calculate the mean of each feature\n",
        "        mfcc_mean = np.mean(mfccs, axis=1)\n",
        "        zcr_mean = np.mean(zcr, axis=1)\n",
        "        mel_mean = np.mean(mel_spectrogram, axis=1)\n",
        "        chroma_mean = np.mean(chroma, axis=1)\n",
        "\n",
        "        # Combine the extracted features into a single feature vector\n",
        "        combined_features = np.concatenate((mfcc_mean, zcr_mean, mel_mean, chroma_mean))\n",
        "\n",
        "        # Ensure that the feature vector shape matches the expected shape\n",
        "        if combined_features.shape[0] < expected_shape[0]:\n",
        "            # Pad the feature vector with zeros\n",
        "            padding = np.zeros(expected_shape[0] - combined_features.shape[0])\n",
        "            combined_features = np.concatenate((combined_features, padding))\n",
        "        elif combined_features.shape[0] > expected_shape[0]:\n",
        "            # Trim the feature vector if it's larger than the expected size\n",
        "            combined_features = combined_features[:expected_shape[0]]\n",
        "\n",
        "        return combined_features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Replace 'new_audio_path' with the path to your new audio file\n",
        "new_audio_path = '/content/drive/MyDrive/Animal_Dataset/Elephant/elephant100.wav'\n",
        "expected_input_shape = (20, 1)  # Update with your model's expected input shape\n",
        "new_audio_features = extract_and_preprocess_features(new_audio_path, expected_input_shape)\n",
        "\n",
        "if new_audio_features is not None:\n",
        "    print(\"Shape before reshaping:\", new_audio_features.shape)\n",
        "    new_audio_features = new_audio_features.reshape(1, *expected_input_shape)\n",
        "    print(\"Shape after reshaping:\", new_audio_features.shape)\n",
        "    predictions = loaded_model.predict(new_audio_features)\n",
        "\n",
        "    # Get the predicted class labels (assuming it's a classification problem)\n",
        "    predicted_class_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Create a mapping of class codes to class labels\n",
        "    class_label_mapping = {\n",
        "        0: 'Birds',\n",
        "        1: 'Elephant',\n",
        "        2: 'Leopard',\n",
        "        3: 'Otter',\n",
        "        4: 'Tiger'\n",
        "    }\n",
        "\n",
        "    # Map the class code to class label for the predicted class\n",
        "    predicted_class_name = class_label_mapping[predicted_class_labels[0]]\n",
        "\n",
        "    # Print the predicted class label for the new audio file\n",
        "    print(f\"Predicted Class Label for {new_audio_path}: {predicted_class_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXJxmodi8rrq",
        "outputId": "8e0433f7-9fea-408b-b3f7-ed6b76ec9cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before reshaping: (20,)\n",
            "Shape after reshaping: (1, 20, 1)\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Predicted Class Label for /content/drive/MyDrive/Animal_Dataset/Elephant/elephant100.wav: Elephant\n"
          ]
        }
      ]
    }
  ]
}